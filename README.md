# natural_language_video_grounding
Retrieve the moments(start and end timestamps) from the videos given sentence query.
It is the replication of the architecture from original paper 
[link](https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_Multi-Stage_Aggregated_Transformer_Network_for_Temporal_Language_Localization_in_Videos_CVPR_2021_paper.pdf).

## Demo
![Video grounding example](demo_output.png)

